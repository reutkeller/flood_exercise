{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ml_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water pixels classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps :\n",
    "1. Collect water pixels into table (consider negative buffer for mroe accuracy)  \n",
    "2. consider - filter pixels based on the values I found in task 2  \n",
    "3. create dataframe  \n",
    "4. split x,y,train,test and train model  \n",
    "5. evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_21428\\2464301796.py:6: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "#|export\n",
    "#|hide\n",
    "\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "import xgboost\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_curve, auc,ConfusionMatrixDisplay\n",
    "\n",
    "\n",
    "from flood_exercise import utils_func\n",
    "from flood_exercise import const_vals as CONST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "class classification_pixels():\n",
    "  \n",
    "  def __init__(self,\n",
    "               path_labels_str : str , #path to the labeled images\n",
    "               path_imgs_str : str , #path to S2 images to be used for train\n",
    "               target_col : str , #name of the target attribute in the dataframe. Will be used for model training\n",
    "               cols_to_drop : list = [None] , # list of columns to be dropped from the dataframe. These columns won't be used to train the model. \n",
    "               test_size : float=CONST.TEST_SIZE , #size of test data\n",
    "               random_state : int = CONST.RANDOM_STATE , #random state , deafult value is set in Cconst_vals module\n",
    "               n_jobs : int=CONST.N_JOBS,\n",
    "\n",
    "               ):\n",
    "    \n",
    "    self.target_col = target_col\n",
    "    self.cols_to_drop = cols_to_drop\n",
    "    self.test_size = test_size\n",
    "    self.random_state = random_state\n",
    "    \n",
    "    self.path_labels = utils_func.load_list_paths(path = path_labels_str , filter_file = True)\n",
    "    self.path_imgs = utils_func.load_list_paths(path = path_imgs_str , filter_file= True)\n",
    "\n",
    "\n",
    "    #collect pixels into dataframe \n",
    "    self.df = self._collect_pixels_to_dataframe_()\n",
    "\n",
    "    self.df_res = self._add_spectral_inidices(self.df)\n",
    "\n",
    "    # split into train and test data for ML model\n",
    "    self.x_train, self.x_test, self.y_train, self.y_test=self._prepare_dataframe_for_train_()\n",
    "\n",
    "    self.best_model = self._train_ml_classification_()\n",
    "\n",
    "    self._evaluate_classification()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "  def _collect_pixels_to_dataframe_(self):\n",
    "    dfs_pixels = []\n",
    "\n",
    "    for label_path in self.path_labels:\n",
    "      id_path = label_path.split(CONST.SPLIT_TILES_NAMES_STR1)[-1].split(CONST.SPLIT_TILES_NAMES_STR2)[1]\n",
    "      \n",
    "      #find the matching S2 image\n",
    "      s2_img_path = [x for x in self.path_imgs if id_path in x]\n",
    "      \n",
    "      if len(s2_img_path)==1:\n",
    "\n",
    "        s2_img = rasterio.open(s2_img_path[0]).read()\n",
    "        cols = rasterio.open(s2_img_path[0]).descriptions + rasterio.open(label_path).descriptions\n",
    "        cols = [str(x) for x in cols]\n",
    "        label_img = rasterio.open(label_path).read()\n",
    "\n",
    "        stacked_img = np.concatenate((s2_img, label_img), axis=0)\n",
    "        \n",
    "        df_pixels = pd.DataFrame(stacked_img.reshape([stacked_img.shape[0],-1]).T)\n",
    "        df_pixels.columns = cols\n",
    "        dfs_pixels.append(df_pixels)\n",
    "\n",
    "      else:\n",
    "        continue\n",
    "      \n",
    "      \n",
    "      df_res = pd.concat(dfs_pixels)\n",
    "\n",
    "      return df_res\n",
    "    \n",
    "  def _add_spectral_inidices(self , \n",
    "                             df : pd.DataFrame , #dataframe with sentinel -2 data\n",
    "                             ):\n",
    "    df[CONST.NDVI_STR] = (df[CONST.NIR_BAND_NAME] - df[CONST.RED_BAND_NAME]) / (df[CONST.NIR_BAND_NAME] + df[CONST.RED_BAND_NAME])\n",
    "    df[CONST.NDWI_STR] = (df[CONST.GREEN_BAND_NAME] - df[CONST.NIR_BAND_NAME]) / (df[CONST.GREEN_BAND_NAME] + df[CONST.NIR_BAND_NAME])\n",
    "\n",
    "    return df\n",
    "  \n",
    "  def _prepare_dataframe_for_train_(self):\n",
    "    \n",
    "    #drop columns that are not relevant for the training (defined by user)\n",
    "    \n",
    "    if self.cols_to_drop[0] != None:\n",
    "\n",
    "      try:\n",
    "        self.df_res=self.df_res.drop(self.cols_to_drop,axis=1)\n",
    "\n",
    "      except Exception as e:\n",
    "        print(f'Could not drop the columns {self.cols_to_drop} with error:{e}')\n",
    "        \n",
    "\n",
    "    #drop null values\n",
    "    self.df_res.dropna(axis=0,inplace=True)\n",
    "\n",
    "    # add 1 to class column , as it has -1 values \n",
    "\n",
    "    self.df_res[self.target_col] = self.df_res[self.target_col] + 1\n",
    "\n",
    "\n",
    "\n",
    "    x = self.df_res.drop(self.target_col,axis=1)\n",
    "    y = self.df_res[self.target_col].values\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "                                                        test_size = self.test_size, \n",
    "                                                        random_state = self.random_state)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "    \n",
    "\n",
    "  def _train_ml_classification_(self):\n",
    "    classifier = xgboost.XGBClassifier()\n",
    "    \n",
    "    XGB_random = RandomizedSearchCV(estimator = classifier, \n",
    "                                   param_distributions = CONST.RANDOM_GRID_XGB,\n",
    "                                   n_iter = CONST.N_ITERATIONS_XGB,\n",
    "                                   cv = CONST.CV_XGB, \n",
    "                                   verbose=CONST.VERBOSE , \n",
    "                                   random_state=CONST.RANDOM_STATE , \n",
    "                                   n_jobs = CONST.N_JOBS)\n",
    "                   \n",
    "    #fit model \n",
    "    XGB_random.fit(self.x_train, self.y_train)\n",
    "\n",
    "  #best params\n",
    "    self.best_params = XGB_random.best_params_\n",
    "    print(f'best params : {self.best_params}')\n",
    "\n",
    "    best_model =xgboost.XGBClassifier(**self.best_params)\n",
    "\n",
    "    best_model.fit(self.x_train, self.y_train)\n",
    "\n",
    "\n",
    "    return best_model\n",
    "  \n",
    "  def _evaluate_classification(self):\n",
    "    \n",
    "    y_pred = self.best_model.predict(self.x_test)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(self.y_test, y_pred)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "\n",
    "    #feature importance\n",
    "    importance_scores = self.best_model.feature_importances_\n",
    "    feature_names = self.x_test.columns.tolist()\n",
    "\n",
    "        # Plot feature importance\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.barh(feature_names, importance_scores)\n",
    "    plt.xlabel('Feature Importance Score')\n",
    "    plt.ylabel('Features')\n",
    "    plt.title('Feature Importance')\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    cm = confusion_matrix(self.y_test, y_pred, normalize='true')\n",
    "    cmd = ConfusionMatrixDisplay(cm,display_labels=['0','1','2'])\n",
    "    cmd.plot(cmap='Blues')\n",
    "    plt.show()   \n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not drop the columns ['qc'] with error:\"['qc'] not found in axis\"\n",
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    }
   ],
   "source": [
    "instance = classification_pixels(path_imgs_str=r\"D:\\git\\flood_exercise\\S2\",\n",
    "                                 path_labels_str=r\"D:\\git\\flood_exercise\\S2_HANDLABELED\",\n",
    "                                 target_col = 'None',\n",
    "                                 cols_to_drop= ['qc'],\n",
    "                                 test_size= 0.25,\n",
    "                                 random_state = 42,\n",
    "\n",
    "                                 )\n",
    "instance.df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
