{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp ml_classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Water pixels classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Steps :\n",
    "1. Collect water pixels into table (consider negative buffer for mroe accuracy)  \n",
    "2. consider - filter pixels based on the values I found in task 2  \n",
    "3. create dataframe  \n",
    "4. split x,y,train,test and train model  \n",
    "5. evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "from nbdev.showdoc import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\AppData\\Local\\Temp\\ipykernel_2872\\4249688180.py:6: DeprecationWarning: \n",
      "Pyarrow will become a required dependency of pandas in the next major release of pandas (pandas 3.0),\n",
      "(to allow more performant data types, such as the Arrow string type, and better interoperability with other libraries)\n",
      "but was not found to be installed on your system.\n",
      "If this would cause problems for you,\n",
      "please provide us feedback at https://github.com/pandas-dev/pandas/issues/54466\n",
      "        \n",
      "  import pandas as pd\n"
     ]
    }
   ],
   "source": [
    "#|export\n",
    "#|hide\n",
    "\n",
    "import rasterio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split,RandomizedSearchCV\n",
    "import xgboost\n",
    "# import geopandas as gpd\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from flood_exercise import utils_func\n",
    "from flood_exercise import const_vals as CONST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "\n",
    "class classification_pixels():\n",
    "  \n",
    "  def __init__(self,\n",
    "               path_labels_str : str , #path to the labeled images\n",
    "               path_imgs_str : str , #path to S2 images to be used for train\n",
    "               target_col : str , #name of the target attribute in the dataframe. Will be used for model training\n",
    "               cols_to_drop : list = [None] , # list of columns to be dropped from the dataframe. These columns won't be used to train the model. \n",
    "               test_size : float=CONST.TEST_SIZE , #size of test data\n",
    "               random_state : int = CONST.RANDOM_STATE , #random state , deafult value is set in Cconst_vals module\n",
    "               n_jobs : int=CONST.N_JOBS,\n",
    "\n",
    "               ):\n",
    "    \n",
    "    self.target_col = target_col\n",
    "    self.cols_to_drop = cols_to_drop\n",
    "    self.test_size = test_size\n",
    "    self.random_state = random_state\n",
    "    \n",
    "    self.path_labels = utils_func.load_list_paths(path = path_labels_str , filter_file = True)\n",
    "    self.path_imgs = utils_func.load_list_paths(path = path_imgs_str , filter_file= True)\n",
    "\n",
    "\n",
    "    #collect pixels into dataframe \n",
    "    self.df_res = self._collect_pixels_to_dataframe_()\n",
    "\n",
    "    # split into train and test data for ML model\n",
    "    self.x_train, self.x_test, self.y_train, self.y_test=self._prepare_dataframe_for_train_()\n",
    "\n",
    "    self._train_ml_classification_()\n",
    "\n",
    "\n",
    "\n",
    "  def _collect_pixels_to_dataframe_(self):\n",
    "    dfs_pixels = []\n",
    "\n",
    "    #TODO remove the 3!\n",
    "    for label_path in self.path_labels[:3]:\n",
    "      id_path = label_path.split(CONST.SPLIT_TILES_NAMES_STR1)[-1].split(CONST.SPLIT_TILES_NAMES_STR2)[1]\n",
    "      \n",
    "      #find the matching S2 image\n",
    "      s2_img_path = [x for x in self.path_imgs if id_path in x]\n",
    "      \n",
    "      if len(s2_img_path)==1:\n",
    "\n",
    "        s2_img = rasterio.open(s2_img_path[0]).read()\n",
    "        cols = rasterio.open(s2_img_path[0]).descriptions + rasterio.open(label_path).descriptions\n",
    "        cols = [str(x) for x in cols]\n",
    "        label_img = rasterio.open(label_path).read()\n",
    "\n",
    "        stacked_img = np.concatenate((s2_img, label_img), axis=0)\n",
    "        \n",
    "        df_pixels = pd.DataFrame(stacked_img.reshape([stacked_img.shape[0],-1]).T)\n",
    "        df_pixels.columns = cols\n",
    "        dfs_pixels.append(df_pixels)\n",
    "\n",
    "      else:\n",
    "        continue\n",
    "      \n",
    "      \n",
    "      df_res = pd.concat(dfs_pixels)\n",
    "\n",
    "      return df_res\n",
    "    \n",
    "  \n",
    "  def _prepare_dataframe_for_train_(self):\n",
    "    \n",
    "    #drop columns that are not relevant for the training (defined by user)\n",
    "    \n",
    "    if self.cols_to_drop[0] != None:\n",
    "\n",
    "      try:\n",
    "        self.df_res=self.df_res.drop(self.cols_to_drop,axis=1)\n",
    "\n",
    "      except Exception as e:\n",
    "        print(f'Could not drop the columns {self.cols_to_drop} with error:{e}')\n",
    "        \n",
    "\n",
    "    #drop null values\n",
    "    self.df_res.dropna(axis=0,inplace=True)\n",
    "\n",
    "    # add 1 to class column , as it has -1 values \n",
    "\n",
    "    self.df_res[self.target_col] = self.df_res[self.target_col] + 1\n",
    "\n",
    "    x = self.df_res.drop(self.target_col,axis=1)\n",
    "    y = self.df_res[self.target_col].values\n",
    "    \n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, \n",
    "                                                        test_size = self.test_size, \n",
    "                                                        random_state = self.random_state)\n",
    "\n",
    "    return x_train, x_test, y_train, y_test\n",
    "    \n",
    "\n",
    "  def _train_ml_classification_(self):\n",
    "    classifier = xgboost.XGBClassifier()\n",
    "    \n",
    "    XGB_random = RandomizedSearchCV(estimator = classifier, \n",
    "                                   param_distributions = CONST.RANDOM_GRID_XGB,\n",
    "                                   n_iter = CONST.N_ITERATIONS_XGB,\n",
    "                                   cv = CONST.CV_XGB, \n",
    "                                   verbose=CONST.VERBOSE , \n",
    "                                   random_state=CONST.RANDOM_STATE , \n",
    "                                   n_jobs = CONST.N_JOBS)\n",
    "                   \n",
    "    #fit model \n",
    "    XGB_random.fit(self.x_train, self.y_train)\n",
    "\n",
    "  #best params\n",
    "    self.best_params = XGB_random.best_params_\n",
    "    print(f'best params : {self.best_params}')\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Could not drop the columns ['qc'] with error:\"['qc'] not found in axis\"\n",
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "\nAll the 500 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n500 fits failed with the following error:\nTraceback (most recent call last):\n  File \"d:\\git\\flood_exercise\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"d:\\git\\flood_exercise\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"d:\\git\\flood_exercise\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1471, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got [-1  0  1]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m instance \u001b[38;5;241m=\u001b[39m \u001b[43mclassification_pixels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_imgs_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mgit\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mflood_exercise\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mS2\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mpath_labels_str\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mD:\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mgit\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mflood_exercise\u001b[39;49m\u001b[38;5;124;43m\\\u001b[39;49m\u001b[38;5;124;43mS2_HANDLABELED\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mtarget_col\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mNone\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mcols_to_drop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mqc\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mtest_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.25\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \n\u001b[0;32m      8\u001b[0m \u001b[43m                                 \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m instance\u001b[38;5;241m.\u001b[39mdf_res\n",
      "Cell \u001b[1;32mIn[4], line 31\u001b[0m, in \u001b[0;36mclassification_pixels.__init__\u001b[1;34m(self, path_labels_str, path_imgs_str, target_col, cols_to_drop, test_size, random_state, n_jobs)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# split into train and test data for ML model\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx_test, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_test\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prepare_dataframe_for_train_()\n\u001b[1;32m---> 31\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_ml_classification_\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[4], line 105\u001b[0m, in \u001b[0;36mclassification_pixels._train_ml_classification_\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     96\u001b[0m   XGB_random \u001b[38;5;241m=\u001b[39m RandomizedSearchCV(estimator \u001b[38;5;241m=\u001b[39m classifier, \n\u001b[0;32m     97\u001b[0m                                  param_distributions \u001b[38;5;241m=\u001b[39m CONST\u001b[38;5;241m.\u001b[39mRANDOM_GRID_XGB,\n\u001b[0;32m     98\u001b[0m                                  n_iter \u001b[38;5;241m=\u001b[39m CONST\u001b[38;5;241m.\u001b[39mN_ITERATIONS_XGB,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    101\u001b[0m                                  random_state\u001b[38;5;241m=\u001b[39mCONST\u001b[38;5;241m.\u001b[39mRANDOM_STATE , \n\u001b[0;32m    102\u001b[0m                                  n_jobs \u001b[38;5;241m=\u001b[39m CONST\u001b[38;5;241m.\u001b[39mN_JOBS)\n\u001b[0;32m    104\u001b[0m   \u001b[38;5;66;03m#fit model \u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m   \u001b[43mXGB_random\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43my_train\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;66;03m#best params\u001b[39;00m\n\u001b[0;32m    108\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbest_params \u001b[38;5;241m=\u001b[39m XGB_random\u001b[38;5;241m.\u001b[39mbest_params_\n",
      "File \u001b[1;32md:\\git\\flood_exercise\\.venv\\Lib\\site-packages\\sklearn\\base.py:1474\u001b[0m, in \u001b[0;36m_fit_context.<locals>.decorator.<locals>.wrapper\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1467\u001b[0m     estimator\u001b[38;5;241m.\u001b[39m_validate_params()\n\u001b[0;32m   1469\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\n\u001b[0;32m   1470\u001b[0m     skip_parameter_validation\u001b[38;5;241m=\u001b[39m(\n\u001b[0;32m   1471\u001b[0m         prefer_skip_nested_validation \u001b[38;5;129;01mor\u001b[39;00m global_skip_validation\n\u001b[0;32m   1472\u001b[0m     )\n\u001b[0;32m   1473\u001b[0m ):\n\u001b[1;32m-> 1474\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfit_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\git\\flood_exercise\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:970\u001b[0m, in \u001b[0;36mBaseSearchCV.fit\u001b[1;34m(self, X, y, **params)\u001b[0m\n\u001b[0;32m    964\u001b[0m     results \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_format_results(\n\u001b[0;32m    965\u001b[0m         all_candidate_params, n_splits, all_out, all_more_results\n\u001b[0;32m    966\u001b[0m     )\n\u001b[0;32m    968\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m results\n\u001b[1;32m--> 970\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_search\u001b[49m\u001b[43m(\u001b[49m\u001b[43mevaluate_candidates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    972\u001b[0m \u001b[38;5;66;03m# multimetric is determined here because in the case of a callable\u001b[39;00m\n\u001b[0;32m    973\u001b[0m \u001b[38;5;66;03m# self.scoring the return type is only known after calling\u001b[39;00m\n\u001b[0;32m    974\u001b[0m first_test_score \u001b[38;5;241m=\u001b[39m all_out[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtest_scores\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32md:\\git\\flood_exercise\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:1914\u001b[0m, in \u001b[0;36mRandomizedSearchCV._run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1912\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_run_search\u001b[39m(\u001b[38;5;28mself\u001b[39m, evaluate_candidates):\n\u001b[0;32m   1913\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Search n_iter candidates from param_distributions\"\"\"\u001b[39;00m\n\u001b[1;32m-> 1914\u001b[0m     \u001b[43mevaluate_candidates\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1915\u001b[0m \u001b[43m        \u001b[49m\u001b[43mParameterSampler\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1916\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparam_distributions\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_iter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_state\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_state\u001b[49m\n\u001b[0;32m   1917\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1918\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32md:\\git\\flood_exercise\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:947\u001b[0m, in \u001b[0;36mBaseSearchCV.fit.<locals>.evaluate_candidates\u001b[1;34m(candidate_params, cv, more_results)\u001b[0m\n\u001b[0;32m    940\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m!=\u001b[39m n_candidates \u001b[38;5;241m*\u001b[39m n_splits:\n\u001b[0;32m    941\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    942\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcv.split and cv.get_n_splits returned \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    943\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minconsistent results. Expected \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    944\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplits, got \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(n_splits, \u001b[38;5;28mlen\u001b[39m(out) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m n_candidates)\n\u001b[0;32m    945\u001b[0m     )\n\u001b[1;32m--> 947\u001b[0m \u001b[43m_warn_or_raise_about_fit_failures\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43merror_score\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    949\u001b[0m \u001b[38;5;66;03m# For callable self.scoring, the return type is only know after\u001b[39;00m\n\u001b[0;32m    950\u001b[0m \u001b[38;5;66;03m# calling. If the return type is a dictionary, the error scores\u001b[39;00m\n\u001b[0;32m    951\u001b[0m \u001b[38;5;66;03m# can now be inserted with the correct key. The type checking\u001b[39;00m\n\u001b[0;32m    952\u001b[0m \u001b[38;5;66;03m# of out will be done in `_insert_error_scores`.\u001b[39;00m\n\u001b[0;32m    953\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mcallable\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscoring):\n",
      "File \u001b[1;32md:\\git\\flood_exercise\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:536\u001b[0m, in \u001b[0;36m_warn_or_raise_about_fit_failures\u001b[1;34m(results, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m num_failed_fits \u001b[38;5;241m==\u001b[39m num_fits:\n\u001b[0;32m    530\u001b[0m     all_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    531\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mAll the \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    532\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt is very likely that your model is misconfigured.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    533\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can try to debug the error by setting error_score=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    534\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    535\u001b[0m     )\n\u001b[1;32m--> 536\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(all_fits_failed_message)\n\u001b[0;32m    538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    539\u001b[0m     some_fits_failed_message \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    540\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mnum_failed_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m fits failed out of a total of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mnum_fits\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    541\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe score on these train-test partitions for these parameters\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    545\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mBelow are more details about the failures:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mfit_errors_summary\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    546\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: \nAll the 500 fits failed.\nIt is very likely that your model is misconfigured.\nYou can try to debug the error by setting error_score='raise'.\n\nBelow are more details about the failures:\n--------------------------------------------------------------------------------\n500 fits failed with the following error:\nTraceback (most recent call last):\n  File \"d:\\git\\flood_exercise\\.venv\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 895, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\n  File \"d:\\git\\flood_exercise\\.venv\\Lib\\site-packages\\xgboost\\core.py\", line 730, in inner_f\n    return func(**kwargs)\n           ^^^^^^^^^^^^^^\n  File \"d:\\git\\flood_exercise\\.venv\\Lib\\site-packages\\xgboost\\sklearn.py\", line 1471, in fit\n    raise ValueError(\nValueError: Invalid classes inferred from unique values of `y`.  Expected: [0 1 2], got [-1  0  1]\n"
     ]
    }
   ],
   "source": [
    "instance = classification_pixels(path_imgs_str=r\"D:\\git\\flood_exercise\\S2\",\n",
    "                                 path_labels_str=r\"D:\\git\\flood_exercise\\S2_HANDLABELED\",\n",
    "                                 target_col = 'None',\n",
    "                                 cols_to_drop= ['qc'],\n",
    "                                 test_size= 0.25,\n",
    "                                 random_state = 42,\n",
    "\n",
    "                                 )\n",
    "instance.df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance.x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance.df_res.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance.df_res.drop('None',axis=1,inplace=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance.df_res['None'].unique().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "instance.df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(test.reshape([test.shape[0],-1]).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(test[13,:,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
